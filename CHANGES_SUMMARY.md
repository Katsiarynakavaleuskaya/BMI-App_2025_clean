# BMI-App_2025_clean - –°–≤–æ–¥–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–π

## üìã –û–ë–ó–û–† –ü–†–û–ï–ö–¢–ê

–ü—Ä–æ–µ–∫—Ç BMI-App_2025_clean - —ç—Ç–æ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ BMI —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**

- `app.py` - FastAPI –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- `bmi_core.py` - –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤ BMI/WHtR
- `providers/` - LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã (ollama, stub, grok, pico)
- `llm.py` - –ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ LLM
- `tests/` - –Æ–Ω–∏—Ç —Ç–µ—Å—Ç—ã

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:**

- Python 3.13.0, FastAPI, Uvicorn
- –í–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ: `.venv/`
- –ü–æ—Ä—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 8001
- Makefile –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–¥–∞—á

## üîß –ù–û–í–´–ï –§–ê–ô–õ–´ –°–û–ó–î–ê–ù–ù–´–ï –í –•–û–î–ï –†–ê–ë–û–¢–´

### 1. ollama_diagnostic.sh - –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Ollama

```bash
#!/bin/bash

echo "üîç Ollama Diagnostic Script"
echo "=========================="
echo "‚è∞ $(date)"
echo ""

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
echo "1Ô∏è‚É£ Ollama Process Status:"
if pgrep -f "ollama serve" > /dev/null; then
    echo "‚úÖ Ollama is running (PID: $(pgrep -f "ollama serve"))"
    echo "   Memory usage: $(ps -o pid,rss,pmem,pcpu,command -p $(pgrep -f "ollama serve") | tail -1)"
else
    echo "‚ùå Ollama is not running"
    exit 1
fi
echo ""

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ API –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
echo "2Ô∏è‚É£ API Connectivity:"
if curl -s --max-time 3 http://localhost:11434/api/version > /dev/null; then
    VERSION=$(curl -s --max-time 3 http://localhost:11434/api/version | jq -r '.version' 2>/dev/null)
    echo "‚úÖ API is responsive (Version: $VERSION)"
else
    echo "‚ùå API is not responsive"
fi
echo ""

# 3. –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
echo "3Ô∏è‚É£ Loaded Models:"
MODELS=$(curl -s --max-time 5 http://localhost:11434/api/tags | jq -r '.models[].name' 2>/dev/null)
if [ $? -eq 0 ]; then
    echo "$MODELS" | while read model; do
        echo "   üì¶ $model"
    done
else
    echo "‚ùå Unable to fetch models"
fi
echo ""

# 4. –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
echo "4Ô∏è‚É£ Response Time Test:"
echo "   Testing with simple prompt..."
START_TIME=$(date +%s)

RESPONSE=$(curl -s --max-time 30 -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d '{"model":"llama3.1:8b","prompt":"Hello","stream":false}' 2>/dev/null)

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

if [ $? -eq 0 ] && [ ! -z "$RESPONSE" ]; then
    echo "   ‚úÖ Response received in ${DURATION}s"
    RESPONSE_TEXT=$(echo "$RESPONSE" | jq -r '.response' 2>/dev/null | head -c 50)
    echo "   üí¨ Response: \"$RESPONSE_TEXT...\""
else
    echo "   ‚ùå Request failed or timed out after ${DURATION}s"
fi
echo ""

# 5. –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
echo "5Ô∏è‚É£ System Resources:"
echo "   CPU Load: $(uptime | awk -F'load average:' '{ print $2 }')"
echo "   Memory: $(free -h 2>/dev/null | grep Mem: || vm_stat | head -2)"
echo "   Disk Space: $(df -h . | tail -1 | awk '{print "Used: "$3"/"$2" ("$5")"}')"
echo ""

echo "üèÅ Diagnostic Complete!"
```

### 2. ollama_monitor.sh - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

```bash
#!/bin/bash

# üîç Ollama Progress Monitor
# –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Ollama

echo "üîÑ Ollama Progress Monitor Started"
echo "================================="
echo "Press Ctrl+C to stop monitoring"
echo ""

LOG_FILE="ollama_monitor.log"
> $LOG_FILE  # –û—á–∏—â–∞–µ–º –ª–æ–≥

monitor_process() {
    while true; do
        TIMESTAMP=$(date '+%H:%M:%S')
        
        # CPU –∏ Memory usage –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama
        OLLAMA_PID=$(pgrep -f "ollama serve")
        if [ ! -z "$OLLAMA_PID" ]; then
            STATS=$(ps -o pid,pcpu,pmem,rss,vsz -p $OLLAMA_PID | tail -1)
            CPU=$(echo $STATS | awk '{print $2}')
            MEM=$(echo $STATS | awk '{print $3}')
            RSS=$(echo $STATS | awk '{print $4}')
            
            # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ –ø–æ—Ä—Ç—É 11434
            CONNECTIONS=$(lsof -i :11434 2>/dev/null | wc -l)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∏ –≤—ã–≤–æ–¥–∏–º
            LOG_ENTRY="[$TIMESTAMP] CPU: ${CPU}% | MEM: ${MEM}% | RSS: ${RSS}KB | Connections: $CONNECTIONS"
            echo "$LOG_ENTRY"
            echo "$LOG_ENTRY" >> $LOG_FILE
            
            # –ï—Å–ª–∏ CPU > 50% –∏–ª–∏ MEM > 10% - –º–æ–¥–µ–ª—å –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
            if (( $(echo "$CPU > 50.0" | bc -l 2>/dev/null || echo "0") )); then
                echo "   üî• HIGH CPU ACTIVITY - Model is processing!"
            elif (( $(echo "$CPU > 10.0" | bc -l 2>/dev/null || echo "0") )); then
                echo "   ‚ö° Medium activity"
            else
                echo "   üò¥ Low activity - idle or waiting"
            fi
        else
            echo "[$TIMESTAMP] ‚ùå Ollama process not found"
        fi
        
        sleep 2
    done
}

# Trap –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
trap 'echo ""; echo "üõë Monitoring stopped. Log saved to: $LOG_FILE"; exit 0' INT

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
monitor_process
```

## ‚öôÔ∏è –ò–ó–ú–ï–ù–ï–ù–ò–Ø –í –°–£–©–ï–°–¢–í–£–Æ–©–ò–• –§–ê–ô–õ–ê–•

### –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ providers/ollama.py

**–í–ê–ñ–ù–û:** –¢–∞–π–º–∞—É—Ç —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 120 —Å–µ–∫—É–Ω–¥ (–±—ã–ª–æ 30)

```python
# –í —Å—Ç—Ä–æ–∫–µ 13:
def __init__(self, endpoint: str = "http://localhost:11434", model: str = "llama3.1:8b", timeout_s: float = 120.0):
```

## üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê

### –í—Ä–µ–º–µ–Ω–∞ –æ—Ç–∫–ª–∏–∫–∞ Ollama

- **–•–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç (–ø–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å):** 30-90 —Å–µ–∫—É–Ω–¥  
- **–ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏:** 15-45 —Å–µ–∫—É–Ω–¥
- **–ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã:** 3-10 —Å–µ–∫—É–Ω–¥
- **–ü–æ–ª–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π ‚Üí —Ä–∞–±–æ—Ç–∞:** 2-5 –º–∏–Ω—É—Ç

### –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

```bash
# –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
./ollama_diagnostic.sh

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
./ollama_monitor.sh

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama
ps aux | grep ollama | grep -v grep

# –ü—Ä–æ–≤–µ—Ä–∫–∞ API Ollama
curl -s http://localhost:11434/api/version

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl -s http://localhost:11434/api/tags | jq .
```

## üîÑ –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï LLM –ü–†–û–í–ê–ô–î–ï–†–û–í

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (–±—ã—Å—Ç—Ä–æ)

```bash
export LLM_PROVIDER=stub
export FEATURE_INSIGHT=1
make run
```

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ (—Å Ollama)

```bash
export LLM_PROVIDER=ollama
export FEATURE_INSIGHT=1
export OLLAMA_ENDPOINT=http://localhost:11434
export OLLAMA_MODEL=llama3.1:8b
make run
```

### –î–ª—è —Ä–∞–±–æ—Ç—ã —Å Grok

```bash
export LLM_PROVIDER=grok
export FEATURE_INSIGHT=1
export GROK_API_KEY=your_api_key
make run
```

## üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

### –£—Å–ø–µ—à–Ω—ã–µ —Ç–µ—Å—Ç—ã —Å stub –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º

```bash
# Health check
curl -s http://127.0.0.1:8001/health
# ‚úÖ {"status":"ok"}

# BMI —Ä–∞—Å—á–µ—Ç
curl -s -X POST http://127.0.0.1:8001/bmi \
  -H "Content-Type: application/json" \
  -d '{"height_m":1.75,"weight_kg":85,"age":30,"gender":"male","pregnant":"no","athlete":"no","user_group":"general","language":"en"}'
# ‚úÖ {"bmi":27.8,"category":"–ò–∑–±—ã—Ç–æ—á–Ω—ã–π –≤–µ—Å","note":"","athlete":false,"group":"general"}

# Plan endpoint
curl -s -X POST http://127.0.0.1:8001/plan \
  -H "Content-Type: application/json" \
  -d '{"height_m":1.75,"weight_kg":85,"age":30,"gender":"male","pregnant":"no","athlete":"no","user_group":"general","language":"en"}'
# ‚úÖ –ü–æ–ª–Ω—ã–π –ø–ª–∞–Ω —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏

# Insight endpoint  
curl -s -X POST http://127.0.0.1:8001/insight \
  -H "Content-Type: application/json" \
  -d '{"text": "Provide health advice for BMI 27.8"}'
# ‚úÖ {"provider":"stub","insight":"[stub @ timestamp] Insight: ..."}
```

## üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ

### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ stub –ø—Ä–æ–≤–∞–π–¥–µ—Ä** - –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
2. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Ollama** —á–µ—Ä–µ–∑ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
3. **–¢–∞–π–º–∞—É—Ç—ã 120+ —Å–µ–∫—É–Ω–¥** –¥–ª—è Ollama

### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

1. **Ollama –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è**
2. **Grok –¥–ª—è –æ–±–ª–∞—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è**
3. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏**

## üöÄ –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ë–´–°–¢–†–û–ì–û –°–¢–ê–†–¢–ê

```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
source .venv/bin/activate

# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å stub
LLM_PROVIDER=stub FEATURE_INSIGHT=1 make run

# –¢–µ—Å—Ç —Å Ollama (—Ç—Ä–µ–±—É–µ—Ç –≤—Ä–µ–º–µ–Ω–∏)
LLM_PROVIDER=ollama FEATURE_INSIGHT=1 make run

# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Ollama
chmod +x ollama_diagnostic.sh ollama_monitor.sh
./ollama_diagnostic.sh

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
make kill
```

## üìà –°–¢–ê–¢–£–° –ü–†–û–ï–ö–¢–ê

‚úÖ **–û—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:** BMI —Ä–∞—Å—á–µ—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –æ—Ç–ª–∏—á–Ω–æ  
‚úÖ **LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:** –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã  
‚úÖ **–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:** –°–æ–∑–¥–∞–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞  
‚úÖ **–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:** –†–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã  
‚úÖ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –í—Å–µ endpoints —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã

**–ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—é —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏!** üéâ
