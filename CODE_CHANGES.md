# –ö–û–ù–ö–†–ï–¢–ù–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø –í –ö–û–î–ï

## 1. –ò–ó–ú–ï–ù–ï–ù–ù–´–ô –§–ê–ô–õ: providers/ollama.py

**–ß—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–æ:** –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º–∞—É—Ç —Å 30 –¥–æ 120 —Å–µ–∫—É–Ω–¥

**–ë–´–õ–û:**
```python
def __init__(self, endpoint: str = "http://localhost:11434", model: str = "llama3.1:8b", timeout_s: float = 30.0):
```

**–°–¢–ê–õ–û:**
```python
def __init__(self, endpoint: str = "http://localhost:11434", model: str = "llama3.1:8b", timeout_s: float = 120.0):
```

**–ü—Ä–∏—á–∏–Ω–∞:** Ollama –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —Ö–æ–ª–æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ (2-5 –º–∏–Ω—É—Ç)

## 2. –ù–û–í–´–ï –§–ê–ô–õ–´

### A. ollama_diagnostic.sh - –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ô –°–ö–†–ò–ü–¢
**–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª:** `/ollama_diagnostic.sh`
**–ü—Ä–∞–≤–∞:** `chmod +x ollama_diagnostic.sh`

```bash
#!/bin/bash

echo "üîç Ollama Diagnostic Script"
echo "=========================="
echo "‚è∞ $(date)"
echo ""

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
echo "1Ô∏è‚É£ Ollama Process Status:"
if pgrep -f "ollama serve" > /dev/null; then
    echo "‚úÖ Ollama is running (PID: $(pgrep -f "ollama serve"))"
    echo "   Memory usage: $(ps -o pid,rss,pmem,pcpu,command -p $(pgrep -f "ollama serve") | tail -1)"
else
    echo "‚ùå Ollama is not running"
    exit 1
fi
echo ""

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ API –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
echo "2Ô∏è‚É£ API Connectivity:"
if curl -s --max-time 3 http://localhost:11434/api/version > /dev/null; then
    VERSION=$(curl -s --max-time 3 http://localhost:11434/api/version | jq -r '.version' 2>/dev/null)
    echo "‚úÖ API is responsive (Version: $VERSION)"
else
    echo "‚ùå API is not responsive"
fi
echo ""

# 3. –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
echo "3Ô∏è‚É£ Loaded Models:"
MODELS=$(curl -s --max-time 5 http://localhost:11434/api/tags | jq -r '.models[].name' 2>/dev/null)
if [ $? -eq 0 ]; then
    echo "$MODELS" | while read model; do
        echo "   üì¶ $model"
    done
else
    echo "‚ùå Unable to fetch models"
fi
echo ""

# 4. –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
echo "4Ô∏è‚É£ Response Time Test:"
echo "   Testing with simple prompt..."
START_TIME=$(date +%s)

RESPONSE=$(curl -s --max-time 30 -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d '{"model":"llama3.1:8b","prompt":"Hello","stream":false}' 2>/dev/null)

END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

if [ $? -eq 0 ] && [ ! -z "$RESPONSE" ]; then
    echo "   ‚úÖ Response received in ${DURATION}s"
    RESPONSE_TEXT=$(echo "$RESPONSE" | jq -r '.response' 2>/dev/null | head -c 50)
    echo "   üí¨ Response: \"$RESPONSE_TEXT...\""
else
    echo "   ‚ùå Request failed or timed out after ${DURATION}s"
fi
echo ""

# 5. –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
echo "5Ô∏è‚É£ System Resources:"
echo "   CPU Load: $(uptime | awk -F'load average:' '{ print $2 }')"
echo "   Memory: $(free -h 2>/dev/null | grep Mem: || vm_stat | head -2)"
echo "   Disk Space: $(df -h . | tail -1 | awk '{print "Used: "$3"/"$2" ("$5")"}')"
echo ""

echo "üèÅ Diagnostic Complete!"
```

### B. ollama_monitor.sh - –ú–û–ù–ò–¢–û–†–ò–ù–ì –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò
**–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª:** `/ollama_monitor.sh`
**–ü—Ä–∞–≤–∞:** `chmod +x ollama_monitor.sh`

```bash
#!/bin/bash

# üîç Ollama Progress Monitor
# –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å Ollama

echo "üîÑ Ollama Progress Monitor Started"
echo "================================="
echo "Press Ctrl+C to stop monitoring"
echo ""

LOG_FILE="ollama_monitor.log"
> $LOG_FILE  # –û—á–∏—â–∞–µ–º –ª–æ–≥

monitor_process() {
    while true; do
        TIMESTAMP=$(date '+%H:%M:%S')
        
        # CPU –∏ Memory usage –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama
        OLLAMA_PID=$(pgrep -f "ollama serve")
        if [ ! -z "$OLLAMA_PID" ]; then
            STATS=$(ps -o pid,pcpu,pmem,rss,vsz -p $OLLAMA_PID | tail -1)
            CPU=$(echo $STATS | awk '{print $2}')
            MEM=$(echo $STATS | awk '{print $3}')
            RSS=$(echo $STATS | awk '{print $4}')
            
            # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ –ø–æ—Ä—Ç—É 11434
            CONNECTIONS=$(lsof -i :11434 2>/dev/null | wc -l)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∏ –≤—ã–≤–æ–¥–∏–º
            LOG_ENTRY="[$TIMESTAMP] CPU: ${CPU}% | MEM: ${MEM}% | RSS: ${RSS}KB | Connections: $CONNECTIONS"
            echo "$LOG_ENTRY"
            echo "$LOG_ENTRY" >> $LOG_FILE
            
            # –ï—Å–ª–∏ CPU > 50% –∏–ª–∏ MEM > 10% - –º–æ–¥–µ–ª—å –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
            if (( $(echo "$CPU > 50.0" | bc -l 2>/dev/null || echo "0") )); then
                echo "   üî• HIGH CPU ACTIVITY - Model is processing!"
            elif (( $(echo "$CPU > 10.0" | bc -l 2>/dev/null || echo "0") )); then
                echo "   ‚ö° Medium activity"
            else
                echo "   üò¥ Low activity - idle or waiting"
            fi
        else
            echo "[$TIMESTAMP] ‚ùå Ollama process not found"
        fi
        
        sleep 2
    done
}

# Trap –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
trap 'echo ""; echo "üõë Monitoring stopped. Log saved to: $LOG_FILE"; exit 0' INT

# –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
monitor_process
```

## 3. –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ù–ê–°–¢–†–û–ô–ö–ò LLM –ü–†–û–í–ê–ô–î–ï–†–û–í

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ STUB (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏):
```bash
export LLM_PROVIDER=stub
export FEATURE_INSIGHT=1
make run
```

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ OLLAMA (–¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞):
```bash
export LLM_PROVIDER=ollama
export FEATURE_INSIGHT=1
export OLLAMA_ENDPOINT=http://localhost:11434
export OLLAMA_MODEL=llama3.1:8b
make run
```

## 4. –¢–ï–°–¢–û–í–´–ï –ö–û–ú–ê–ù–î–´ API

### –¢–µ—Å—Ç BMI endpoint:
```bash
curl -s -X POST http://127.0.0.1:8001/bmi \
  -H "Content-Type: application/json" \
  -d '{"height_m":1.75,"weight_kg":85,"age":30,"gender":"male","pregnant":"no","athlete":"no","user_group":"general","language":"en"}'
```

### –¢–µ—Å—Ç Insight endpoint:
```bash
curl -s -X POST http://127.0.0.1:8001/insight \
  -H "Content-Type: application/json" \
  -d '{"text": "Provide health advice for BMI 27.8"}'
```

### –¢–µ—Å—Ç Plan endpoint:
```bash
curl -s -X POST http://127.0.0.1:8001/plan \
  -H "Content-Type: application/json" \
  -d '{"height_m":1.75,"weight_kg":85,"age":30,"gender":"male","pregnant":"no","athlete":"no","user_group":"general","language":"en"}'
```

## 5. –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ï –ö–û–ú–ê–ù–î–´

```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
source .venv/bin/activate

# –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ Ollama
./ollama_diagnostic.sh

# –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
./ollama_monitor.sh

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ Ollama
ps aux | grep ollama | grep -v grep

# –ü—Ä–æ–≤–µ—Ä–∫–∞ API Ollama
curl -s http://localhost:11434/api/version

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
make kill
```

## 6. –û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´

‚úÖ **Ollama —Ö–æ–ª–æ–¥–Ω—ã–π —Å—Ç–∞—Ä—Ç:** 2-5 –º–∏–Ω—É—Ç - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ  
‚úÖ **Stub –ø—Ä–æ–≤–∞–π–¥–µ—Ä:** –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏  
‚úÖ **–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:** –ß–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã  
‚úÖ **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:** –°–æ–∑–¥–∞–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏  
‚úÖ **–í—Å–µ endpoints:** –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç  

**–ü—Ä–æ–µ–∫—Ç –≥–æ—Ç–æ–≤ –∫ –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ!**